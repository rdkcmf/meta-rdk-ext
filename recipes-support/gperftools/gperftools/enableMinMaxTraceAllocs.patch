Date: May 10 19:59:54 2018

From: 071e7f04649d797db5fa9a20f9a864e62333afd1 May 14 13:40:26 2018

Subject: [PATCH] RDKSYSINTSW-3564 : Patch gperftools to keep track of range-based allocs

	For memory intensive applications reduce amount of
	allocations to keep track of to allow an app to properly start up.

Source: COMCAST

Upstream-Status: Pending

Signed-off-by: Sergei Danilchuk <sergei_danilchuk@cable.comcast.com>
---


diff --git a/src/heap-profiler.cc b/src/heap-profiler.cc
index 33a25ac..dd1fce6 100755
--- a/src/heap-profiler.cc
+++ b/src/heap-profiler.cc
@@ -91,6 +91,13 @@ using STL_NAMESPACE::sort;
 // The thread-safety of the profiler depends on these being immutable
 // after main starts, so don't change them.
 //----------------------------------------------------------------------
+DEFINE_int64(heap_profile_min_trace_allocation,
+             EnvToInt64("HEAP_PROFILE_MIN_ALLOC", 0),
+             "The size of minimum allocation to trace.");
+
+DEFINE_int64(heap_profile_max_trace_allocation,
+             EnvToInt64("HEAP_PROFILE_MAX_ALLOC", LLONG_MAX),
+             "The size of maximum allocation to trace.");
 
 DEFINE_int64(heap_profile_allocation_interval,
              EnvToInt64("HEAP_PROFILE_ALLOCATION_INTERVAL", 1 << 30 /*1GB*/),
@@ -316,13 +323,16 @@ static void MaybeDumpProfileLocked() {
 
 // Record an allocation in the profile.
 static void RecordAlloc(const void* ptr, size_t bytes, int skip_count) {
-  // Take the stack trace outside the critical section.
-  void* stack[HeapProfileTable::kMaxStackDepth];
-  int depth = HeapProfileTable::GetCallerStackTrace(skip_count + 1, stack);
-  SpinLockHolder l(&heap_lock);
-  if (is_on) {
-    heap_profile->RecordAlloc(ptr, bytes, depth, stack);
-    MaybeDumpProfileLocked();
+  if (bytes >= FLAGS_heap_profile_min_trace_allocation && bytes <= FLAGS_heap_profile_max_trace_allocation)
+  {
+    // Take the stack trace outside the critical section.
+    void* stack[HeapProfileTable::kMaxStackDepth];
+    int depth = HeapProfileTable::GetCallerStackTrace(skip_count + 1, stack);
+    SpinLockHolder l(&heap_lock);
+    if (is_on) {
+      heap_profile->RecordAlloc(ptr, bytes, depth, stack);
+      MaybeDumpProfileLocked();
+    }
   }
 }
 
